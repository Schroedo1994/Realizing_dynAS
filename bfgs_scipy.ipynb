{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "import math\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "from scipy.optimize.optimize import _prepare_scalar_function\n",
    "from scipy.optimize.optimize import vecnorm\n",
    "from scipy.optimize.linesearch import (line_search_wolfe1, line_search_wolfe2,\n",
    "                         line_search_wolfe2 as line_search,\n",
    "                         LineSearchWarning)\n",
    "from scipy.optimize.optimize import _line_search_wolfe12\n",
    "from scipy.optimize.optimize import _LineSearchError\n",
    "from scipy.optimize.optimize import OptimizeResult\n",
    "from scipy.optimize.optimize import _status_message\n",
    "from scipy.optimize._differentiable_functions import ScalarFunction, FD_METHODS\n",
    "\n",
    "import IOHexperimenter as IOH\n",
    "from IOHexperimenter import IOH_function\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "from os.path import basename\n",
    "import shutil\n",
    "from shutil import make_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFGS:\n",
    "    \n",
    "    def __init__(self, budget):\n",
    "        \n",
    "        #parameter settings\n",
    "        self.budget = budget\n",
    "        self.d = 1\n",
    "        self.gtol = 1e-5 #Gradient norm must be less than `gtol` before successful termination\n",
    "        self.norm = np.inf #Order of norm (Inf is max, -Inf is min)\n",
    "        self.disp = False\n",
    "        self.eps = math.sqrt(np.finfo(float).eps) #If `jac is None` the absolute step size used for numerical approximation of the jacobian via forward differences.\n",
    "        self.return_all = True\n",
    "        self.jac = None\n",
    "        self.finite_diff_rel_step = None\n",
    "    \n",
    "        \n",
    "    def __call__(self, func):\n",
    "        \n",
    "        #Initialization\n",
    "        self.d = func.number_of_variables\n",
    "        evalcount = 0\n",
    "        eval_budget = self.budget * self.d\n",
    "        \n",
    "        retall = self.return_all\n",
    "      \n",
    "        \n",
    "        #initialize first point x0\n",
    "        x0 = np.zeros(self.d)\n",
    "        x_opt = None\n",
    "        f_opt = np.inf\n",
    "        for i in range (0, self.d):\n",
    "            x0[i] = rd.uniform(-5,5)\n",
    "            \n",
    "        sf = _prepare_scalar_function(func, x0, self.jac, epsilon=self.eps,\n",
    "                              finite_diff_rel_step=self.finite_diff_rel_step)\n",
    "        \n",
    "        f = sf.fun\n",
    "        myfprime = sf.grad\n",
    "        \n",
    "        old_fval = f(x0)\n",
    "        evalcount = evalcount + 1\n",
    "        gfk = myfprime(x0)\n",
    "        \n",
    "        k = 0\n",
    "        N = len(x0)\n",
    "        I = np.eye(N, dtype=int)\n",
    "        Hk = I\n",
    "        \n",
    "        # Sets the initial step guess to dx ~ 1\n",
    "        old_old_fval = old_fval + np.linalg.norm(gfk) / 2\n",
    "        \n",
    "        xk = x0\n",
    "        if retall:\n",
    "            allvecs = [x0]\n",
    "        warnflag = 0\n",
    "        gnorm = vecnorm(gfk, ord=self.norm)\n",
    "        \n",
    "    \n",
    "        \n",
    "        while (gnorm > self.gtol) and (evalcount < eval_budget) and (func.final_target_hit == False):\n",
    "            \n",
    "            pk = -np.dot(Hk, gfk)\n",
    "            \n",
    "            try:\n",
    "                alpha_k, fc, gc, old_fval, old_old_fval, gfkp1 = \\\n",
    "                     _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n",
    "                                          old_fval, old_old_fval, amin=1e-100, amax=1e100)\n",
    "            except _LineSearchError:\n",
    "                # Line search failed to find a better solution.\n",
    "                warnflag = 2\n",
    "                break\n",
    "            \n",
    "            # evalcount increment here?\n",
    "            evaclount = evalcount + fc\n",
    "            evaclount = evalcount + gc\n",
    "                \n",
    "            xkp1 = xk + alpha_k * pk\n",
    "            if retall:\n",
    "                allvecs.append(xkp1)\n",
    "                \n",
    "            sk = xkp1 - xk\n",
    "            xk = xkp1\n",
    "            if gfkp1 is None:\n",
    "                gfkp1 = myfprime(xkp1)\n",
    "                # evalcount increment here?\n",
    "                evaclount = evalcount + 1\n",
    "           \n",
    "            yk = gfkp1 - gfk\n",
    "            gfk = gfkp1\n",
    "            k += 1\n",
    "            \n",
    "            if not np.isfinite(old_fval):\n",
    "                # We correctly found +-Inf as optimal value, or something went wrong\n",
    "                warnflag = 2\n",
    "                break\n",
    "            \n",
    "            gnorm = vecnorm(gfk, ord=self.norm)\n",
    "            if (gnorm <= self.gtol):\n",
    "                break\n",
    "            \n",
    "            try:  # this was handled in numeric, let it remaines for more safety\n",
    "                rhok = 1.0 / (np.dot(yk, sk))\n",
    "            except ZeroDivisionError:\n",
    "                rhok = 1000.0\n",
    "            if self.disp:\n",
    "                print(\"Divide-by-zero encountered: rhok assumed large\")\n",
    "            if np.isinf(rhok):  # this is patch for NumPy\n",
    "                rhok = 1000.0\n",
    "            if self.disp:\n",
    "                print(\"Divide-by-zero encountered: rhok assumed large\")\n",
    "                \n",
    "            A1 = I - sk[:, np.newaxis] * yk[np.newaxis, :] * rhok\n",
    "            A2 = I - yk[:, np.newaxis] * sk[np.newaxis, :] * rhok\n",
    "            Hk = np.dot(A1, np.dot(Hk, A2)) + (rhok * sk[:, np.newaxis] *\n",
    "                                                     sk[np.newaxis, :])\n",
    "            \n",
    "            \n",
    "        fval = old_fval\n",
    "\n",
    "        if warnflag == 2:\n",
    "            msg = _status_message['pr_loss']\n",
    "        elif k >= eval_budget:\n",
    "            warnflag = 1\n",
    "            msg = _status_message['maxiter']\n",
    "        elif np.isnan(gnorm) or np.isnan(fval) or np.isnan(xk).any():\n",
    "            warnflag = 3\n",
    "            msg = _status_message['nan']\n",
    "        else:\n",
    "            msg = _status_message['success']\n",
    "\n",
    "        if self.disp:\n",
    "            print(\"%s%s\" % (\"Warning: \" if warnflag != 0 else \"\", msg))\n",
    "            print(\"         Current function value: %f\" % fval)\n",
    "            print(\"         Iterations: %d\" % k)\n",
    "            print(\"         Function evaluations: %d\" % sf.nfev)\n",
    "            print(\"         Gradient evaluations: %d\" % sf.ngev)\n",
    "\n",
    "\n",
    "        result = OptimizeResult(fun=fval, jac=gfk, hess_inv=Hk, nfev=sf.nfev,\n",
    "                        njev=sf.ngev, status=warnflag,\n",
    "                        success=(warnflag == 0), message=msg, x=xk,\n",
    "                        nit=k)\n",
    "\n",
    "        if retall:\n",
    "            result['allvecs'] = allvecs\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter date-time, format ddmm-hhmm 1409-1340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running single-threaded\n",
      "1 12 2.9493445963274944e-13\n",
      "2 36 7.4360574868678e-10\n",
      "3 39 72.63025687796166\n",
      "4 72 129.34089089115966\n",
      "5 273 16.603528200305057\n",
      "6 153 2.2257000936205704e-09\n",
      "7 3 93.04435028473078\n",
      "8 147 5.395135642286734e-09\n",
      "9 123 9.700859282631788e-09\n",
      "10 206 9.346491036125658e-06\n",
      "11 189 1.0965142754135027e-07\n",
      "12 45 6.073409048299639e-10\n",
      "13 225 18.19764103292527\n",
      "14 261 1.2954636895012496e-06\n",
      "15 99 398.9018072968266\n",
      "16 201 216.3164525709442\n",
      "17 102 100.25668504921823\n",
      "18 102 6453.899994268251\n",
      "19 147 12.842646162611674\n",
      "20 45 6.641585059696809e-12\n",
      "21 42 2.7779884071349468\n",
      "22 27 21.779461996470946\n",
      "23 141 8.450359001817906\n",
      "24 66 3.4966692574243767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/dschroeder/Documents/Master Computer Science/Master_Thesis/code_and_data/experiments/BFGS/experiment1409-1340.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fIDs = []\n",
    "for fid in range (1,25):\n",
    "    fIDs.append(fid)\n",
    "    \n",
    "from IOHexperimenter import IOHexperimenter\n",
    "exp = IOHexperimenter()\n",
    "exp.initialize_BBOB(fIDs,[1],[2,5,10], 1)\n",
    "path = \"/Users/dschroeder/Documents/Master Computer Science/Master_Thesis/code_and_data/experiments/\"\n",
    "experiment_ID = input(\"enter date-time, format ddmm-hhmm\")\n",
    "experiment_name =  \"BFGS/experiment\" + experiment_ID\n",
    "exp.set_logger_location(path + experiment_name, \"run\")\n",
    "exp([BFGS(10000)])\n",
    "#create a ZIP file for IOHprofiler upload\n",
    "shutil.make_archive(path + experiment_name,\"zip\", path + experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_epsilon = math.sqrt(np.finfo(float).eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
