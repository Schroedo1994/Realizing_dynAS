{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "import math\n",
    "import sys\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "from scipy.optimize.optimize import _prepare_scalar_function\n",
    "from scipy.optimize.optimize import vecnorm\n",
    "from scipy.optimize.linesearch import (line_search_wolfe1, line_search_wolfe2,\n",
    "                         line_search_wolfe2 as line_search,\n",
    "                         LineSearchWarning)\n",
    "from scipy.optimize.optimize import _line_search_wolfe12\n",
    "from scipy.optimize.optimize import _LineSearchError\n",
    "from scipy.optimize.optimize import OptimizeResult\n",
    "from scipy.optimize.optimize import _status_message\n",
    "from scipy.optimize._differentiable_functions import ScalarFunction, FD_METHODS\n",
    "\n",
    "import IOHexperimenter as IOH\n",
    "from IOHexperimenter import IOH_function\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "from os.path import basename\n",
    "import shutil\n",
    "from shutil import make_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFGS:\n",
    "    \n",
    "    def __init__(self, budget):\n",
    "        \n",
    "        #parameter settings\n",
    "        self.budget = budget\n",
    "        self.d = 1\n",
    "        self.gtol = 1e-10 #Gradient norm must be less than `gtol` before successful termination\n",
    "        self.norm = np.inf #Order of norm (Inf is max, -Inf is min)\n",
    "        self.disp = False\n",
    "        self.eps = math.sqrt(np.finfo(float).eps) #If `jac is None` the absolute step size used for numerical approximation of the jacobian via forward differences.\n",
    "        self.return_all = True\n",
    "        self.jac = None\n",
    "        self.finite_diff_rel_step = None\n",
    "    \n",
    "        \n",
    "    def __call__(self, func):\n",
    "        \n",
    "        #Initialization\n",
    "        self.d = func.number_of_variables\n",
    "        eval_budget = self.budget * self.d\n",
    "        \n",
    "        retall = self.return_all\n",
    "      \n",
    "        \n",
    "        #initialize first point x0\n",
    "        x0 = np.zeros(self.d)\n",
    "        x_opt = None\n",
    "        f_opt = np.inf\n",
    "        for i in range (0, self.d):\n",
    "            x0[i] = rd.uniform(-5,5)\n",
    "            \n",
    "        sf = _prepare_scalar_function(func, x0, self.jac, epsilon=self.eps,\n",
    "                              finite_diff_rel_step=self.finite_diff_rel_step)\n",
    "        \n",
    "        f = sf.fun\n",
    "        myfprime = sf.grad\n",
    "        \n",
    "        old_fval = f(x0)\n",
    "        gfk = myfprime(x0)\n",
    "        \n",
    "        k = 0\n",
    "        N = len(x0)\n",
    "        I = np.eye(N, dtype=int)\n",
    "        Hk = I\n",
    "        \n",
    "        # Sets the initial step guess to dx ~ 1\n",
    "        old_old_fval = old_fval + np.linalg.norm(gfk) / 2\n",
    "        \n",
    "        xk = x0\n",
    "        if retall:\n",
    "            allvecs = [x0]\n",
    "        warnflag = 0\n",
    "        gnorm = vecnorm(gfk, ord=self.norm)\n",
    "        \n",
    "        #(gnorm > self.gtol) and \n",
    "        \n",
    "        while (func.evaluations < eval_budget) and not func.final_target_hit:\n",
    "            \n",
    "            pk = -np.dot(Hk, gfk)\n",
    "            \n",
    "            #target precision\n",
    "            #if (func.best_so_far_precision < 0.01)\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                alpha_k, fc, gc, old_fval, old_old_fval, gfkp1 = \\\n",
    "                     _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n",
    "                                          old_fval, old_old_fval, amin=1e-100, amax=1e100)\n",
    "                \n",
    "            except _LineSearchError:\n",
    "                # Line search failed to find a better solution.\n",
    "                warnflag = 2\n",
    "                break\n",
    "                \n",
    "            xkp1 = xk + alpha_k * pk\n",
    "            if retall:\n",
    "                allvecs.append(xkp1)\n",
    "                \n",
    "            sk = xkp1 - xk\n",
    "            xk = xkp1\n",
    "            if gfkp1 is None:\n",
    "                gfkp1 = myfprime(xkp1)\n",
    "           \n",
    "            yk = gfkp1 - gfk\n",
    "            gfk = gfkp1\n",
    "            k += 1\n",
    "            \n",
    "            if not np.isfinite(old_fval):\n",
    "                # We correctly found +-Inf as optimal value, or something went wrong\n",
    "                warnflag = 2\n",
    "                break\n",
    "            \n",
    "            gnorm = vecnorm(gfk, ord=self.norm)\n",
    "            if (gnorm <= self.gtol):\n",
    "                break\n",
    "            \n",
    "            try:  # this was handled in numeric, let it remaines for more safety\n",
    "                rhok = 1.0 / (np.dot(yk, sk))\n",
    "            except ZeroDivisionError:\n",
    "                rhok = 1000.0\n",
    "            if self.disp:\n",
    "                print(\"Divide-by-zero encountered: rhok assumed large\")\n",
    "            if np.isinf(rhok):  # this is patch for NumPy\n",
    "                rhok = 1000.0\n",
    "            if self.disp:\n",
    "                print(\"Divide-by-zero encountered: rhok assumed large\")\n",
    "                \n",
    "            A1 = I - sk[:, np.newaxis] * yk[np.newaxis, :] * rhok\n",
    "            A2 = I - yk[:, np.newaxis] * sk[np.newaxis, :] * rhok\n",
    "            Hk = np.dot(A1, np.dot(Hk, A2)) + (rhok * sk[:, np.newaxis] *\n",
    "                                                     sk[np.newaxis, :])\n",
    "            \n",
    "            \n",
    "        print((func.evaluations, func.final_target_hit, eval_budget, gnorm, self.gtol))\n",
    "        print(func.best_so_far_precision)\n",
    "        \n",
    "        fval = old_fval\n",
    "\n",
    "        if warnflag == 2:\n",
    "            msg = _status_message['pr_loss']\n",
    "        elif k >= eval_budget:\n",
    "            warnflag = 1\n",
    "            msg = _status_message['maxiter']\n",
    "        elif np.isnan(gnorm) or np.isnan(fval) or np.isnan(xk).any():\n",
    "            warnflag = 3\n",
    "            msg = _status_message['nan']\n",
    "        else:\n",
    "            msg = _status_message['success']\n",
    "\n",
    "        if self.disp:\n",
    "            print(\"%s%s\" % (\"Warning: \" if warnflag != 0 else \"\", msg))\n",
    "            print(\"         Current function value: %f\" % fval)\n",
    "            print(\"         Iterations: %d\" % k)\n",
    "            print(\"         Function evaluations: %d\" % sf.nfev)\n",
    "            print(\"         Gradient evaluations: %d\" % sf.ngev)\n",
    "\n",
    "\n",
    "        result = OptimizeResult(fun=fval, jac=gfk, hess_inv=Hk, nfev=sf.nfev,\n",
    "                        njev=sf.ngev, status=warnflag,\n",
    "                        success=(warnflag == 0), message=msg, x=xk,\n",
    "                        nit=k)\n",
    "\n",
    "        if retall:\n",
    "            result['allvecs'] = allvecs\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fIDs = []\n",
    "for fid in range (1,25):\n",
    "    fIDs.append(fid)\n",
    "    \n",
    "from IOHexperimenter import IOHexperimenter\n",
    "exp = IOHexperimenter()\n",
    "exp.initialize_BBOB(fIDs,[1],[2,5,10], 1)\n",
    "path = \"/Users/dschroeder/Documents/Master Computer Science/Master_Thesis/code_and_data/experiments/\"\n",
    "now = datetime.datetime.now()\n",
    "experiment_ID = str(now.day) + \"-\" + str(now.month) + \"-\" + str(now.strftime('%H')) + str(now.strftime('%M')) + str(now.strftime('%S'))\n",
    "experiment_name =  \"BFGS/experiment\" + experiment_ID\n",
    "exp.set_logger_location(path + experiment_name, \"run\")\n",
    "exp([BFGS(10000)])\n",
    "#create a ZIP file for IOHprofiler upload\n",
    "shutil.make_archive(path + experiment_name,\"zip\", path + experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
